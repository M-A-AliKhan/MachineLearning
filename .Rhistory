load("C:/Users/Ali/Downloads/activity.csv")
echo = true
data <- read.csv("activity.csv", header = TRUE, sep = ",", na.strings = "NA")
summary (data)
# Loading and preprocessing the data
## Loading the data:
file <- read.csv("activity.csv", header = T, sep = ",", na.strings = "NA")
## Preprocessing the data:
echo = TRUE
summary(file)
echo = TRUE
echo = TRUE
file$date <- as.Date(file$date, format = "%Y-%m-%d")
file$interval <- factor(file$interval)
echo = TRUE
head(file)
##What is mean total number of steps taken per day?
#Calculating the total number of steps taken per day:
echo = TRUE
NA_index <- is.na(as.character(file$steps))
file_no_NA <- file[!NA_index,]
head(file_no_NA)
echo = TRUE
steps_each_day <- aggregate(steps ~ date, data = file_no_NA, sum)
colnames(steps_each_day) <- c("date", "steps")
# Making histogram of the total number of steps taken each day:
echo = TRUE
hist(as.numeric(steps_each_day$steps), breaks = 20, col = "red", xlab = "Number of Steps", main= "-Histogram- total number of steps taken each day")
# CalculatING and reportING the mean and median:
echo = TRUE
mean(steps_each_day$steps)
echo = TRUE
median(steps_each_day$steps)
## Average daily activity pattern:
# Making a time series plot
echo = TRUE
steps_per_interval <- aggregate(file_no_NA$steps, by=list(interval=file_no_NA$interval), FUN=mean)
colnames(steps_per_interval) <- c("interval", "average_steps")
echo = TRUE
plot(as.integer(levels(steps_per_interval$interval)), steps_per_interval$average_steps, type="l",
xlab = "Interval", ylab = "Average Number of Steps", main = "-Average- Daily Activity Pattern",  col ="blue")
#  Maximum number of steps:
echo = TRUE
max_no_steps <- max(steps_per_interval$average_steps)
max_no_steps
# Averaging 5-minute interval:
echo = TRUE
intervale_maximum_steps<-steps_per_interval[which.max(steps_per_interval$average_steps),]$interval
intervale_maximum_steps
## Imputing missing values
# Calculatingthe total number of missing values in all variables:
echo = TRUE
sum(is.na(as.character(file$steps)))
sum(is.na(as.character(file$interval)))
sum(is.na(as.character(file$date)))
#Strategy of the missing values, missing values are replaced by the mean of that 5-minute interval:
echo = TRUE
NA_index <- which(is.na(as.character(data$steps)))
whole_data <- file
whole_data[NA_index, ]$steps<-unlist(lapply(NA_index, FUN=function(NA_index){
steps_per_interval[file[NA_index,]$interval==steps_per_interval$interval,]$average_steps}))
summary(whole_data)
str(whole_data)
# Histogram of the total number of steps taken each day:
echo = TRUE
steps_each_day_complete <- aggregate(steps ~ date, data = whole_data, sum)
colnames(steps_each_day_complete) <- c("date", "steps")
hist(as.numeric(steps_each_day_complete$steps), breaks = 20, col = "red", xlab = "Number of Steps", main= "-Histogram- total number of steps taken each day")
# Calculating the mean and median total number of steps taken per day:
echo = TRUE
mean(steps_each_day_complete$steps)
median(steps_each_day_complete$steps)
## Differences in activity patterns between weekdays and weekends:
echo = TRUE
whole_data$day <- as.factor(weekdays(whole_data$date))
whole_data$is_weekday <- ifelse(!(whole_data$day %in% c("Saturday","Sunday")), TRUE, FALSE)
weekdays_data <- whole_data[whole_data$is_weekday,]
steps_per_interval_weekdays <- aggregate(weekdays_data$steps, by=list(interval=weekdays_data$interval), FUN=mean)
weekends_data <- whole_data[!whole_data$is_weekday,]
steps_per_interval_weekends <- aggregate(weekends_data$steps, by=list(interval=weekends_data$interval), FUN=mean)
colnames(steps_per_interval_weekdays) <- c("interval", "average_steps")
colnames(steps_per_interval_weekends) <- c("interval", "average_steps")
steps_per_interval_weekdays$day <- "Weekday"
steps_per_interval_weekends$day <- "Weekend"
week_data <- rbind(steps_per_interval_weekends, steps_per_interval_weekdays)
week_data$day <- as.factor(week_data$day)
#Making the plot
library(lattice)
xyplot(average_steps ~  interval | day, data = week_data, layout = c(1,2), type ="l", ylab="Number of Steps")
```{r}
## url contains the location of the datase
url <- "http://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf"
if(!file.exists("./repdata-data-StormData.csv.bz2")) {
## Dowload the dataset
a <- download.file(url,method="curl",destfile="./repdata-data-StormData.csv.bz2")
##bzfile is used to read a bz2 compressed file
}
data <- read.csv(bzfile("repdata-data-StormData.csv.bz2"))
names(data)
```
```{r}
## url contains the location of the datase
url <- "http://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf"
if(!file.exists("./repdata_data_StormData.csv.bz2")) {
## Dowload the dataset
a <- download.file(url,method="curl",destfile="./repdata_data_StormData.csv.bz2")
##bzfile is used to read a bz2 compressed file
}
data <- read.csv(bzfile("repdata_data_StormData.csv.bz2"))
names(data)
```
```{r}
## url contains the location of the datase
url <- "http://d396qusza40orc.cloudfront.net/repdata%2Fpeer2_doc%2Fpd01016005curr.pdf"
if(!file.exists("./repdata_data_StormData.csv.bz2")) {
## Dowload the dataset
a <- download.file(url,method="curl",destfile="./repdata_data_StormData.csv.bz2")
##bzfile is used to read a bz2 compressed file
}
data <- read.csv(bzfile("repdata-data-StormData.csv.bz2"))
names(data)
```
## url contains the location of the datase
url <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
if(!file.exists("./repdata_data_StormData.csv.bz2")) {
## Dowload the dataset
a <- download.file(url,method="curl",destfile="./repdata_data_StormData.csv.bz2")
##bzfile is used to read a bz2 compressed file
}
data <- read.csv(bzfile("repdata_data_StormData.csv.bz2"))
names(data)
```
## url contains the location of the datase
url <- "http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
if(!file.exists("./repdata_data_StormData.csv.bz2")) {
## Dowload the dataset
a <- download.file(url,method="curl",destfile="./repdata_data_StormData.csv.bz2")
##bzfile is used to read a bz2 compressed file
}
data <- read.csv(bzfile("repdata_data_StormData.csv.bz2"))
names(data)
```
## url contains the location of the datase
url <- "http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
if(!file.exists("./repdata-data-StormData.csv.bz2")) {
## Dowload the dataset
a <- download.file(url,method="curl",destfile="./repdata-data-StormData.csv.bz2")
##bzfile is used to read a bz2 compressed file
}
data <- read.csv(bzfile("repdata-data-StormData.csv.bz2"))
names(data)
```
## url contains the location of the datase
url <- "http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
if(!file.exists("./repdata-data-StormData.csv.bz2")) {
## Dowload the dataset
a <- download.file(url,method="curl",destfile="./repdata-data-StormData.csv.bz2")
##bzfile is used to read a bz2 compressed file
}
data <- read.csv(bzfile("repdata-data-StormData.csv.bz2"))
names(data)
```
## url contains the location of the datase
url <- "http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
if(!file.exists("./repdata-data-StormData.csv.bz2")) {
## Dowload the dataset
a <- download.file(url,method="curl",destfile="./repdata-data-StormData.csv.bz2")
##bzfile is used to read a bz2 compressed file
}
data <- read.csv(bzfile("repdata-data-StormData.csv.bz2"))
names(data)
## url contains the location of the datase
url <- "http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
if(!file.exists("./repdata-data-StormData.csv.bz2")) {
## Dowload the dataset
a <- download.file(url,method="curl",destfile="./repdata-data-StormData.csv.bz2")
##bzfile is used to read a bz2 compressed file
}
data <- read.csv(bzfile("repdata-data-StormData.csv.bz2"))
names(data)
library("ggplot2", lib.loc="~/R/win-library/3.1")
# Dowloading data if it's not already done
if(!file.exists("stormData.csv.bz2")) {
download.file("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2",
destfile = "stormData.csv.bz2", method = "curl")
}
# Loading data
dsNOAA <- read.csv(bzfile("stormData.csv.bz2"), sep=",", header=T)
# Dowloading data if it's not already done
if(!file.exists("stormData.csv.bz2")) {
download.file("http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2",
destfile = "stormData.csv.bz2", method = "curl")
}
# Loading data
dsNOAA <- read.csv(bzfile("stormData.csv.bz2"), sep=",", header=T)
# Dowloading data if it's not already done
if(!file.exists("stormData.csv.bz2")) {
download.file("http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2",
destfile = "stormData.csv.bz2", method = "curl")
}
# Loading data
dsNOAA <- read.csv(unzip("stormData.csv.bz2"), sep=",", header=T)
# Dowloading data if it's not already done
if(!file.exists("stormData.csv.bz2")) {
download.file("http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2",
destfile = "stormData.csv.bz2", method = "auto")
}
# Loading data
dsNOAA <- read.csv(bzfile("stormData.csv.bz2"), sep=",", header=T)
# Dowloading data if it's not already done
if(!file.exists("repdata-data-StormData.csv.bz2")) {
download.file("http://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2",
destfile = "repdata-data-StormData.csv.bz2", method = "auto")
}
# Loading data
dsNOAA <- read.csv(bzfile("repdata-data-StormData.csv.bz2"), sep=",", header=T)
# Subset (NOAA) storm database
tidyNOAA <- dsNOAA[,c('EVTYPE','FATALITIES','INJURIES', 'PROPDMG', 'PROPDMGEXP', 'CROPDMG', 'CROPDMGEXP')]
# Convert H, K, M, B units to calculate Property Damage
tidyNOAA$PROPDMGNUM = 0
tidyNOAA[tidyNOAA$PROPDMGEXP == "H", ]$PROPDMGNUM = tidyNOAA[tidyNOAA$PROPDMGEXP == "H", ]$PROPDMG * 10^2
tidyNOAA[tidyNOAA$PROPDMGEXP == "K", ]$PROPDMGNUM = tidyNOAA[tidyNOAA$PROPDMGEXP == "K", ]$PROPDMG * 10^3
tidyNOAA[tidyNOAA$PROPDMGEXP == "M", ]$PROPDMGNUM = tidyNOAA[tidyNOAA$PROPDMGEXP == "M", ]$PROPDMG * 10^6
tidyNOAA[tidyNOAA$PROPDMGEXP == "B", ]$PROPDMGNUM = tidyNOAA[tidyNOAA$PROPDMGEXP == "B", ]$PROPDMG * 10^9
# Convert H, K, M, B units to calculate Crop Damage
tidyNOAA$CROPDMGNUM = 0
tidyNOAA[tidyNOAA$CROPDMGEXP == "H", ]$CROPDMGNUM = tidyNOAA[tidyNOAA$CROPDMGEXP == "H", ]$CROPDMG * 10^2
tidyNOAA[tidyNOAA$CROPDMGEXP == "K", ]$CROPDMGNUM = tidyNOAA[tidyNOAA$CROPDMGEXP == "K", ]$CROPDMG * 10^3
tidyNOAA[tidyNOAA$CROPDMGEXP == "M", ]$CROPDMGNUM = tidyNOAA[tidyNOAA$CROPDMGEXP == "M", ]$CROPDMG * 10^6
tidyNOAA[tidyNOAA$CROPDMGEXP == "B", ]$CROPDMGNUM = tidyNOAA[tidyNOAA$CROPDMGEXP == "B", ]$CROPDMG * 10^9
# import ggplot2 library to plot the result
library(ggplot2)
# plot number of fatalities with the most harmful event type
fatalities <- aggregate(FATALITIES ~ EVTYPE, data=tidyNOAA, sum)
fatalities <- fatalities[order(-fatalities$FATALITIES), ][1:10, ]
fatalities$EVTYPE <- factor(fatalities$EVTYPE, levels = fatalities$EVTYPE)
ggplot(fatalities, aes(x = EVTYPE, y = FATALITIES)) +
geom_bar(stat = "identity", fill = "red", las = 3) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
xlab("Event Type") + ylab("Fatalities") + ggtitle("Number of fatalities by top 10 Weather Events")
# import ggplot2 library to plot the result
library(ggplot2)
# plot number of injuries with the most harmful event type
injuries <- aggregate(INJURIES ~ EVTYPE, data=tidyNOAA, sum)
injuries <- injuries[order(-injuries$INJURIES), ][1:10, ]
injuries$EVTYPE <- factor(injuries$EVTYPE, levels = injuries$EVTYPE)
ggplot(injuries, aes(x = EVTYPE, y = INJURIES)) +
geom_bar(stat = "identity", fill = "red", las = 3) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
xlab("Event Type") + ylab("Injuries") + ggtitle("Number of injuries by top 10 Weather Events")
# import ggplot2 library to plot the result
library(ggplot2)
# plot number of damages with the most harmful event type
damages <- aggregate(PROPDMGNUM + CROPDMGNUM ~ EVTYPE, data=tidyNOAA, sum)
names(damages) = c("EVTYPE", "TOTALDAMAGE")
damages <- damages[order(-damages$TOTALDAMAGE), ][1:10, ]
damages$EVTYPE <- factor(damages$EVTYPE, levels = damages$EVTYPE)
ggplot(damages, aes(x = EVTYPE, y = TOTALDAMAGE)) +
geom_bar(stat = "identity", fill = "red", las = 3) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
xlab("Event Type") + ylab("Damages ($)") + ggtitle("Property & Crop Damages by top 10 Weather Events")
# import ggplot2 library to plot the result
library(ggplot2)
# plot number of fatalities with the most harmful event type
fatalities <- aggregate(FATALITIES ~ EVTYPE, data=tidyNOAA, sum)
fatalities <- fatalities[order(-fatalities$FATALITIES), ][1:10, ]
fatalities$EVTYPE <- factor(fatalities$EVTYPE, levels = fatalities$EVTYPE)
ggplot(fatalities, aes(x = EVTYPE, y = FATALITIES)) +
geom_bar(stat = "identity", fill = "green", las = 3) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
xlab("Event Type") + ylab("Fatalities") + ggtitle("Number of fatalities by top 10 Weather Events")
# import ggplot2 library to plot the result
library(ggplot2)
# plot number of damages with the most harmful event type
damages <- aggregate(PROPDMGNUM + CROPDMGNUM ~ EVTYPE, data=tidyNOAA, sum)
names(damages) = c("EVTYPE", "TOTALDAMAGE")
damages <- damages[order(-damages$TOTALDAMAGE), ][1:10, ]
damages$EVTYPE <- factor(damages$EVTYPE, levels = damages$EVTYPE)
ggplot(damages, aes(x = EVTYPE, y = TOTALDAMAGE)) +
geom_bar(stat = "identity", fill = "blue", las = 3) +
theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
xlab("Event Type") + ylab("Damages ($)") + ggtitle("Property & Crop Damages by top 10 Weather Events")
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
q()
```{r, echo=FALSE}
lambda<-0.2
x <- NULL
num_exponentials <- 40
set.seed(1000)
for(i in 1:1000) {
x <- c(x, mean(rexp(num_exponentials, lambda)))
}
library(caret); library(randomForest); library(rpart); library(rpart.plot); set.seed(1234)
install.packages("caret")
library(caret); library(randomForest); library(rpart); library(rpart.plot); set.seed(1234)
library(caret); library(randomForest); library(rpart); library(rpart.plot); set.seed(1234)
install.packages("randomForest")
library(caret); library(randomForest); library(rpart); library(rpart.plot); set.seed(1234)
install.packages("rpart.plot")
library(caret); library(randomForest); library(rpart); library(rpart.plot); set.seed(1234)
```
library(caret)
library(rpart)
library(rpart)
library(RColorBrewer)
library(rattle)
install.packages("rattle")
library(rattle)
library(randomForest)
set.seed(12345)
library(caret); library(rpart) ; library(rpart); library(RColorBrewer); library(rattle); library(randomForest); set.seed(12345)
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
setwd("C:/Users/Ali/Desktop/RProjects/MachineLearning")
testingset <- read.csv("pml-testing", na.strings=c("NA","#DIV/0!", ""))
testingset <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!", ""))
testingset <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!", ""))
testingset <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!", ""))
read.csv("C:/Users/Ali/Desktop/RProjects/MachineLearning/trainingdata.csv", na.strings=c("NA","#DIV/0!", ""))
read.csv("C:/Users/Ali/Desktop/RProjects/MachineLearning/trainingdata.csv", na.strings=c("NA","#DIV/0!", ""))
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
dim(myTraining)
fancyRpartPlot(modFitA1)
RpartPlot(modFitA1)
fancyRpartPlot(modFitA1)
fancyRpartPlot(modFitA1)
```
fancyRpartPlot(modFitA1)
fancyRpart.Plot(modFitA1)
fancyRpartPlot(modFitA1)
Rpart.Plot(modFitA1)
Rpart.Plot(modFitA1)
fancyRpartPlot(modFitA1)
fancyRpartPlot(modFitA1)
fancyRpartPlot(modFitA1)
fancyRpartPlot(modFitA1)
rpart.plot(modFitA1)
predictionsA1 <- predict(modFitA1, myTesting, type = "class")
confusionMatrix(predictionsA1, myTesting$classe)
confusionMatrix(predictionsA1, myTesting$classe)
predictionA1 <- predict(modFitA1, myTesting, type = "class")
confusionMatrix(predictionA1, myTesting$classe)
confusionMatrix(predictionA1, myTesting$class)
library(lattice); library(ggplot2); library(caret); library(randomForest); library(rpart); library(rpart.plot); library(RColorBrewer); library(rattle)
modFitB1 <- randomForest(classe ~. , data=myTraining)
```
predictionB1 <- predict(modFitB1, myTesting, type = "class")
confusionMatrix(predictionB1, myTesting$classe)
confusionMatrix(predictionB1, myTesting$classe)
confusionMatrix(predictB1, myTesting$classe)
confusionMatrix(predictionB1, myTesting$classe)
confusionMatrix(predictionB1, myTesting)
confusionMatrix(predictionB1)
predictionB1 <- predict(modFitB1, myTesting, type = "class")
modFitB1 <- randomForest(classe ~. , data=myTraining)
confusionMatrix(predictionB1, TestTrainingSet$classe)
confusionMatrix(predictionB1, myTesting$classe)
confusionMatrix(predictionA1, myTesting$classe)
confusionMatrix(predictionA1, Testing$classe)
confusionMatrix(predictionA1, Testing$classe)
predictionsA1 <- predict(modFitA1, myTesting, type = "class")
predictionsA1 <- predict(modFitA1, myTesting, type = "class")
confusionMatrix(predictionsA1, myTesting$classe)$table
install.packages("e1071")
